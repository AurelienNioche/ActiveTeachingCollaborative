# TODO list

* Define properly paper's objectives (center around 
cold start?)

* Dig out the paper draft

* Run `oneshot_artificial_human_like.py`

* Check what to keep between 
`minibatch-optim-hyperparam.ipynb` and
`minibatch-optim-hyperparam-2.ipynb`

### What do we have?

* Ultra simple toy example with minibatch

`minibatch-demo-with-minibatch-scale.ipynb`

* Ultra simple toy example with normalizing flows

(see other project: 
https://github.com/AurelienNioche/NormalizingFlowsTutorial)

* Toy example with normalizing flow 
and minibatch working: 

`minibatch-demo-with-minibatch-scale.ipynb` 
("scale" because take into account 
batch size / dataset size)

* An example of inference in teaching context 
WITHOUT minibatch working 
`run_oneshot_artificial`

* An example of inference in teaching context 
WITHOUT minibatch with actual experimental data 
=> does it work? difficult to say...

* An example of inference in teaching context 
WITHOUT minibatch with artificial data but using 
the parameters inferred using the 
actual experimental data 
=> does not work so well!




